{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1477478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb17e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc9594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8bd4ec-4aa4-4cb8-a338-3b691c501990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b848823666e4d67b32b527f6a454938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[doi] scanning dirs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6282db43c44ef498f58be057e99ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[doi] reading CSVs:   0%|          | 0/1615 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3d7ef116ae41f9aa6309a7b4821df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e5b599c627461e8af9ec87b25e28d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32298b9f2f348ae8f7b45aaad017210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5616d5dbba224f99a1d1b9355363c64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[isbn] scanning dirs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fb84cb84314df2af30954c845c51c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[isbn] reading CSVs:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d4c30741c64b4bb532598eb2bf4b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7452edcffdad4e02b1a62f715572c28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865ff4535fd74eee8a8185a1008aa91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1 — imports and tqdm setup\n",
    "from __future__ import annotations\n",
    "import os, ast, functools\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm  # notebook-friendly tqdm\n",
    "tqdm.pandas()  # enables .progress_apply on pandas objects\n",
    "\n",
    "# gender-guesser (aka \"gender-guesser\" package: gender.Detector)\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "# optional secondary detector\n",
    "try:\n",
    "    from gender_detector.gender_detector import GenderDetector\n",
    "    _HAS_DETECTOR2 = True\n",
    "except Exception:\n",
    "    GenderDetector = None  # type: ignore\n",
    "    _HAS_DETECTOR2 = False\n",
    "\n",
    "# Cell 2 — detector initialization (global so cached inference can see them)\n",
    "_DETECTOR1 = gender.Detector(case_sensitive=False)\n",
    "_DETECTOR2 = GenderDetector('uk') if _HAS_DETECTOR2 else None\n",
    "\n",
    "\n",
    "# Cell 3 — helpers (unchanged semantics; notebook-safe)\n",
    "def _map_gender_guesser(label: Optional[str]) -> str:\n",
    "    \"\"\"\n",
    "    Map gender-guesser outputs to {'male','female','unknown'}.\n",
    "    \"\"\"\n",
    "    m = (label or \"\").strip().lower()\n",
    "    if m in {\"male\", \"mostly_male\"}:\n",
    "        return \"male\"\n",
    "    if m in {\"female\", \"mostly_female\"}:\n",
    "        return \"female\"\n",
    "    # 'andy' (androgynous) and anything else -> unknown\n",
    "    return \"unknown\"\n",
    "\n",
    "def _map_gender_detector(label: Optional[str]) -> str:\n",
    "    \"\"\"\n",
    "    Map gender-detector outputs to {'male','female','unknown'}.\n",
    "    \"\"\"\n",
    "    l = (label or \"\").strip().lower()\n",
    "    return l if l in {\"male\", \"female\"} else \"unknown\"\n",
    "\n",
    "@functools.lru_cache(maxsize=8192)\n",
    "def infer_gender_offline(name: Optional[str]) -> str:\n",
    "    \"\"\"\n",
    "    Deterministic offline gender inference with strict precedence:\n",
    "        1) gender-guesser (primary)\n",
    "        2) gender-detector (secondary; only if primary yields 'unknown' and available)\n",
    "    Returns one of {'male','female','unknown'}.\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str) or not name.strip():\n",
    "        return \"unknown\"\n",
    "    first = name.strip().split()[0]\n",
    "\n",
    "    # Primary\n",
    "    g1_raw = _DETECTOR1.get_gender(first)\n",
    "    g1 = _map_gender_guesser(g1_raw)\n",
    "    if g1 != \"unknown\":\n",
    "        return g1\n",
    "\n",
    "    # Fallback\n",
    "    if _HAS_DETECTOR2 and _DETECTOR2 is not None:\n",
    "        try:\n",
    "            g2_raw = _DETECTOR2.guess(first) if hasattr(_DETECTOR2, \"guess\") else _DETECTOR2.get_gender(first)  # type: ignore[attr-defined]\n",
    "        except Exception:\n",
    "            g2_raw = None\n",
    "        g2 = _map_gender_detector(g2_raw)\n",
    "        if g2 != \"unknown\":\n",
    "            return g2\n",
    "\n",
    "    return \"unknown\"\n",
    "\n",
    "def _infer_list_gender(forenames: Optional[List[str]]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Apply infer_gender_offline elementwise to a list of forenames.\n",
    "    Non-list inputs are treated as empty.\n",
    "    \"\"\"\n",
    "    if not isinstance(forenames, list):\n",
    "        return []\n",
    "    # tqdm for lists (gives a small per-row bar; can be verbose — usually better to keep only the Series/DataFrame bars)\n",
    "    return [infer_gender_offline(x if isinstance(x, str) else \"\") for x in forenames]\n",
    "\n",
    "def _counts(gs: List[str]) -> pd.Series:\n",
    "    return pd.Series({\n",
    "        \"number_male\":    sum(g == \"male\" for g in gs),\n",
    "        \"number_female\":  sum(g == \"female\" for g in gs),\n",
    "        \"number_unknown\": sum(g == \"unknown\" for g in gs),\n",
    "        \"number_people\":  len(gs),\n",
    "    })\n",
    "\n",
    "def extract_forenames(author_list_str):\n",
    "    \"\"\"Safely parse the author list and extract forenames.\"\"\"\n",
    "    try:\n",
    "        authors = ast.literal_eval(author_list_str)\n",
    "        return [\n",
    "            a[\"first_name\"]\n",
    "            for a in authors\n",
    "            if isinstance(a, dict) and a.get(\"first_name\")\n",
    "        ]\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        return []\n",
    "\n",
    "\n",
    "# Cell 4 — main function with tqdm at each heavy step\n",
    "def return_merged(identifier: str) -> pd.DataFrame:\n",
    "    base_path = f\"/home/jinx/Dropbox/ics_work/ics_taxonomies/data/dimensions_outputs/api/raw/{identifier}/202510\"\n",
    "\n",
    "    # Build list of CSVs with a progress bar over directories\n",
    "    # (os.walk itself is a generator; materialize and wrap with tqdm)\n",
    "    walk_list = list(os.walk(base_path))\n",
    "    csv_files = []\n",
    "    for root, _, files in tqdm(walk_list, desc=f\"[{identifier}] scanning dirs\"):\n",
    "        for f in files:\n",
    "            if f.endswith(\".csv\"):\n",
    "                csv_files.append(os.path.join(root, f))\n",
    "\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {base_path}\")\n",
    "\n",
    "    # Read CSVs with a progress bar; attach source filename\n",
    "    frames = []\n",
    "    for f in tqdm(csv_files, desc=f\"[{identifier}] reading CSVs\"):\n",
    "        frames.append(pd.read_csv(f).assign(source_file=os.path.basename(f)))\n",
    "\n",
    "    # Concatenate (fast; no need for tqdm here)\n",
    "    df_all = pd.concat(frames, ignore_index=False)\n",
    "\n",
    "    # Apply functions with pandas-native progress bars\n",
    "    df_all[\"author_forenames\"] = df_all[\"authors\"].progress_apply(\n",
    "        extract_forenames\n",
    "    )\n",
    "\n",
    "    df_all[\"author_genders\"] = df_all[\"author_forenames\"].progress_apply(\n",
    "        _infer_list_gender\n",
    "    )\n",
    "\n",
    "    df_all[[\"number_male\",\n",
    "            \"number_female\",\n",
    "            \"number_unknown\",\n",
    "            \"number_people\"]] = df_all[\"author_genders\"].progress_apply(_counts)\n",
    "\n",
    "    # Optional quick peek without printing entire frame\n",
    "    return df_all\n",
    "\n",
    "\n",
    "# Cell 5 — run with progress\n",
    "df_dois = return_merged(\"doi\")\n",
    "df_isbn = return_merged(\"isbn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c726c65-b4e8-4440-a3ae-3ffc4b83748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outputs = pd.read_excel('../../ics_taxonomies/data/raw/raw_ref_outputs_data.xlsx', skiprows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a1e514a-f863-4b7d-b403-0dda017dfa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outputs_w_doi = pd.merge(df_outputs, df_dois, how='left', left_on='DOI', right_on='doi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "276da7a4-4cf8-44a1-acc2-f0c9d06a4156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outputs_mdoi = pd.merge(df_outputs, df_dois, how='left',\n",
    "                           left_on='DOI', right_on='doi')\n",
    "df_outputs_w_doi = df_outputs_mdoi[df_outputs_mdoi['doi'].notnull()]\n",
    "df_outputs_wo_doi = df_outputs_mdoi[df_outputs_mdoi['doi'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0131b17-de79-4f73-867c-4f3b7c27141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outputs_wo_doi = df_outputs_wo_doi.drop(['Unnamed: 0', 'id', 'authors_count', 'category_for_2020',\n",
    "       'dimensions_url', 'doi', 'isbn', 'year', 'authors', 'source_file',\n",
    "       'author_forenames', 'author_genders', 'number_male', 'number_female',\n",
    "       'number_unknown', 'number_people'], axis=1\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e15a12c-3192-48d8-80e7-1f6d655d1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_isbn(isbn):\n",
    "    if pd.isna(isbn):\n",
    "        return None\n",
    "    if isinstance(isbn, list):  # normalize each element if list\n",
    "        return [re.sub(r'[^0-9Xx]', '', str(x)).upper() for x in isbn]\n",
    "    else:\n",
    "        return re.sub(r'[^0-9Xx]', '', str(isbn)).upper()\n",
    "\n",
    "df_outputs_wo_doi['ISBN_norm'] = df_outputs_wo_doi['ISBN'].apply(normalize_isbn)\n",
    "df_isbn['isbn_norm'] = df_isbn['isbn'].apply(normalize_isbn)\n",
    "df_isbn_exploded = df_isbn.explode('isbn_norm')\n",
    "df_outputs_wo_doi_w_isbn = pd.merge(\n",
    "    df_outputs_wo_doi,\n",
    "    df_isbn_exploded,\n",
    "    how='left',\n",
    "    left_on='ISBN_norm',\n",
    "    right_on='isbn_norm'\n",
    ")\n",
    "df_outputs_wo_doi_w_isbn = df_outputs_wo_doi_w_isbn[df_outputs_wo_doi_w_isbn['isbn_norm'].notnull()].drop('ISBN_norm', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce3158ed-0a11-4a47-a28e-f0ed108e3b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3553 135203 185286\n"
     ]
    }
   ],
   "source": [
    "print(len(df_outputs_wo_doi_w_isbn), len(df_outputs_w_doi), len(df_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "489da8ef-940f-44e5-b7eb-00dcda4e7b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_outputs_w_doi, df_outputs_wo_doi_w_isbn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ead3b566-fcfb-4681-9a35-627703c76c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = df_concat[['Institution UKPRN code', 'Institution name', 'Main panel',\n",
    "                       'Unit of assessment number', 'Unit of assessment name', 'REF2ID', 'authors',\n",
    "                       'category_for_2020', 'year', 'doi', 'isbn',\n",
    "                       'isbn_norm','authors_count', 'author_forenames', 'author_genders',\n",
    "                       'number_male', 'number_female', 'number_unknown', 'number_people']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589bb09-d85e-4ae5-91dd-d32d2ffbe23b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78bc9aae-b591-403c-9dfb-9b5af7c4f870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136016\n"
     ]
    }
   ],
   "source": [
    "df_concat.to_csv('../../ics_taxonomies/data/dimensions_outputs/outputs_concat_with_any_number_authors.csv')\n",
    "print(len(df_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67501ef8-039b-4a2f-94d4-703dbf59b1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136016\n"
     ]
    }
   ],
   "source": [
    "df_concat = df_concat[df_concat['number_people']>0]\n",
    "df_concat.to_csv('../../ics_taxonomies/data/dimensions_outputs/outputs_concat_with_positive_authors.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
